AWSTemplateFormatVersion: "2010-09-09"
Description: Provision EC2 for k8s

Parameters:
  KeyName:
    Description: The EC2 Key Pair to allow SSH Access to the instance
    Type: "AWS::EC2::KeyPair::KeyName"
  MyIP:
    Description: IP address allowed to access EC2
    Type: String
  Ec2ImageId:
    Type: AWS::SSM::Parameter::Value<String>
    Default: /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2
  Ec2InstanceType:
    Type: String
    Default: t3.small

Resources:
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.5.0.0/16
      Tags:
        - Key: Name
          Value: vpc-cf

  IGW:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: igw-cf

  # IGWをVPCにアタッチ
  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref IGW

  PubSubA:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: ap-northeast-1a
      VpcId: !Ref VPC
      CidrBlock: 10.5.10.0/24
      Tags:
        - Key: Name
          Value: pub-sub-a-cf

  PubSubRT:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: pub-sub-rt-cf

  # PubSub-インターネット間のルーティング
  PubSubToInternet:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PubSubRT
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref IGW

  # ルートテーブルをサブネットに関連付け
  AssoPubSubART:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PubSubA
      RouteTableId: !Ref PubSubRT

  # HAProxy用EC2インスタンス
  EC2HAProxy:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref Ec2ImageId
      KeyName: !Ref KeyName
      InstanceType: !Ref Ec2InstanceType
      IamInstanceProfile: !Ref EC2InstanceProfile
      NetworkInterfaces:
        - AssociatePublicIpAddress: "true"
          DeviceIndex: "0"
          SubnetId: !Ref PubSubA
          PrivateIpAddress: 10.5.10.40
          GroupSet:
            - !Ref EC2MasterSG
      UserData: !Base64 |
        #!/bin/bash
        set -euo pipefail
        # hostnameとhostsの設定
        hostnamectl set-hostname ec2-haproxy-cf
        cat <<EOF | sudo tee -a /etc/hosts
        10.5.10.11 ec2-mster-1-cf
        10.5.10.12 ec2-mster-2-cf
        10.5.10.13 ec2-mster-3-cf
        10.5.10.21 ec2-worker-1-cf
        10.5.10.40 ec2-haproxy-cf
        EOF
        # HAProxyのインストールと設定
        yum install -y haproxy
        systemctl enable haproxy
        grep -q -F 'net.ipv4.ip_nonlocal_bind=1' /etc/sysctl.conf || echo 'net.ipv4.ip_nonlocal_bind=1' >> /etc/sysctl.conf
        cat >/etc/haproxy/haproxy.cfg <<EOF
        global
            log /dev/log    local0
            log 127.0.0.1   local2
            chroot /var/lib/haproxy
            #stats socket /run/haproxy/admin.sock mode 660 level admin
            stats timeout 30s
            user haproxy
            group haproxy
            daemon
            # Default SSL material locations
            ca-base /etc/ssl/certs
            crt-base /etc/ssl/private
            # Default ciphers to use on SSL-enabled listening sockets.
            # For more information, see ciphers(1SSL). This list is from:
            #  https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
            ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS
            ssl-default-bind-options no-sslv3
        defaults
            log global
            mode    tcp
            option  tcplog
            option  dontlognull
                timeout connect 5000
                timeout client  50000
                timeout server  50000
                #errorfile 400 /etc/haproxy/errors/400.http
                #errorfile 403 /etc/haproxy/errors/403.http
                #errorfile 408 /etc/haproxy/errors/408.http
                #errorfile 500 /etc/haproxy/errors/500.http
                #errorfile 502 /etc/haproxy/errors/502.http
                #errorfile 503 /etc/haproxy/errors/503.http
                #errorfile 504 /etc/haproxy/errors/504.http
        frontend k8s
            bind 10.5.10.40:6443
            default_backend k8s_backend
        backend k8s_backend
            balance roundrobin
            mode tcp
            server ec2-mster-1-cf 10.5.10.11:6443 check inter 1000
            server ec2-mster-2-cf 10.5.10.12:6443 check inter 1000
            server ec2-mster-3-cf 10.5.10.13:6443 check inter 1000
        EOF
        # rsyslogを使ったhaproxyログ出力設定
        sed -i.back -e "s:^#\(\$ModLoad imudp\)$:\1:" -e "s:^#\(\$UDPServerRun 514\)$:\1:" /etc/rsyslog.conf
        touch /etc/rsyslog.d/haproxy.conf
        cat <<"EOF" > /etc/rsyslog.d/haproxy.conf
        $ModLoad imudp
        $UDPServerRun 514
        local2.info /var/log/haproxy/haproxy.log
        local0.info /var/log/haproxy/admin.log
        # don't log anywhere else
        local0.* ~
        local2.* ~
        EOF
        # hostname設定のため再起動
        shutdown -r now
      Tags:
          - Key: Name
            Value: ec2-haproxy-cf

  # k8s master nodes
  EC2Master1: 
    Type: AWS::EC2::Instance
    Properties: 
      ImageId: !Ref Ec2ImageId
      KeyName: !Ref KeyName
      InstanceType: !Ref Ec2InstanceType
      IamInstanceProfile: !Ref EC2InstanceProfile
      NetworkInterfaces: 
        - AssociatePublicIpAddress: "true"
          DeviceIndex: "0"
          SubnetId: !Ref PubSubA
          PrivateIpAddress: 10.5.10.11
          GroupSet:
            - !Ref EC2MasterSG
      UserData: !Base64 |
        #!/bin/bash
        # hostnameとhostsの設定 
        hostnamectl set-hostname ec2-master-1-cf
        cat <<EOF | sudo tee -a /etc/hosts
        10.5.10.11 ec2-mster-1-cf
        10.5.10.12 ec2-mster-2-cf
        10.5.10.13 ec2-mster-3-cf
        10.5.10.21 ec2-worker-1-cf
        10.5.10.40 ec2-haproxy-cf
        EOF
        # dockerとkubeadmのインストール
        yum install -y docker && systemctl enable docker
        cat <<EOF | sudo tee -a /etc/yum.repos.d/kubernetes.repo
        [kubernetes]
        name=Kubernetes
        baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
        enabled=1
        gpgcheck=1
        repo_gpgcheck=1
        gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
        EOF
        yum install -y kubeadm
        # hostname設定のため再起動
        shutdown -r now
      Tags:
          - Key: Name
            Value: ec2-mster-1-cf
  EC2Master2:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref Ec2ImageId
      KeyName: !Ref KeyName
      InstanceType: !Ref Ec2InstanceType
      IamInstanceProfile: !Ref EC2InstanceProfile
      NetworkInterfaces:
        - AssociatePublicIpAddress: "true"
          DeviceIndex: "0"
          SubnetId: !Ref PubSubA
          PrivateIpAddress: 10.5.10.12
          GroupSet:
            - !Ref EC2MasterSG
      UserData: !Base64 |
        #!/bin/bash
        # hostnameとhostsの設定 
        hostnamectl set-hostname ec2-master-2-cf
        cat <<EOF | sudo tee -a /etc/hosts
        10.5.10.11 ec2-mster-1-cf
        10.5.10.12 ec2-mster-2-cf
        10.5.10.13 ec2-mster-3-cf
        10.5.10.21 ec2-worker-1-cf
        10.5.10.40 ec2-haproxy-cf
        EOF
        # dockerとkubeadmのインストール
        yum install -y docker && systemctl enable docker
        cat <<EOF | sudo tee -a /etc/yum.repos.d/kubernetes.repo
        [kubernetes]
        name=Kubernetes
        baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
        enabled=1
        gpgcheck=1
        repo_gpgcheck=1
        gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
        EOF
        yum install -y kubeadm
        # hostname設定のため再起動
        shutdown -r now
      Tags:
          - Key: Name
            Value: ec2-mster-2-cf
  EC2Master3:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref Ec2ImageId
      KeyName: !Ref KeyName
      InstanceType: !Ref Ec2InstanceType
      IamInstanceProfile: !Ref EC2InstanceProfile
      NetworkInterfaces:
        - AssociatePublicIpAddress: "true"
          DeviceIndex: "0"
          SubnetId: !Ref PubSubA
          PrivateIpAddress: 10.5.10.13
          GroupSet:
            - !Ref EC2MasterSG
      UserData: !Base64 |
        #!/bin/bash
        # hostnameとhostsの設定 
        hostnamectl set-hostname ec2-master-3-cf
        cat <<EOF | sudo tee -a /etc/hosts
        10.5.10.11 ec2-mster-1-cf
        10.5.10.12 ec2-mster-2-cf
        10.5.10.13 ec2-mster-3-cf
        10.5.10.21 ec2-worker-1-cf
        10.5.10.40 ec2-haproxy-cf
        EOF
        # dockerとkubeadmのインストール
        yum install -y docker && systemctl enable docker
        cat <<EOF | sudo tee -a /etc/yum.repos.d/kubernetes.repo
        [kubernetes]
        name=Kubernetes
        baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
        enabled=1
        gpgcheck=1
        repo_gpgcheck=1
        gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
        EOF
        yum install -y kubeadm
        # hostname設定のため再起動
        shutdown -r now
      Tags:
          - Key: Name
            Value: ec2-mster-3-cf

  # k8s worker node
  EC2Worker1:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref Ec2ImageId
      KeyName: !Ref KeyName
      InstanceType: !Ref Ec2InstanceType
      IamInstanceProfile: !Ref EC2InstanceProfile
      NetworkInterfaces:
        - AssociatePublicIpAddress: "true"
          DeviceIndex: "0"
          SubnetId: !Ref PubSubA
          PrivateIpAddress: 10.5.10.21
          GroupSet:
            - !Ref EC2WorkerSG
      UserData: !Base64 |
        #!/bin/bash
        # hostnameとhostsの設定 
        hostnamectl set-hostname ec2-worker-1-cf
        cat <<EOF | sudo tee -a /etc/hosts
        10.5.10.11 ec2-mster-1-cf
        10.5.10.12 ec2-mster-2-cf
        10.5.10.13 ec2-mster-3-cf
        10.5.10.21 ec2-worker-1-cf
        10.5.10.40 ec2-haproxy-cf
        EOF
        # dockerとkubeadmのインストール
        yum install -y docker && systemctl enable docker
        cat <<EOF | sudo tee -a /etc/yum.repos.d/kubernetes.repo
        [kubernetes]
        name=Kubernetes
        baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
        enabled=1
        gpgcheck=1
        repo_gpgcheck=1
        gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
        EOF
        yum install -y kubeadm
        # hostname設定のため再起動
        shutdown -r now
      Tags:
          - Key: Name
            Value: ec2-worker-1-cf

  # k8s master node用SG
  EC2MasterSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: ec2-master-sg-cf
      GroupDescription: Allow SSH and HTTP and kubernetes master access
      VpcId: !Ref VPC
      SecurityGroupIngress:
        # ssh
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: !Ref MyIP
        # k8s
        - IpProtocol: tcp
          FromPort: 6443
          ToPort: 6443
          Description: k8s API server
          CidrIp: 10.5.0.0/16
        - IpProtocol: tcp
          FromPort: 2379
          ToPort: 2379
          Description: etcd
          CidrIp: 10.5.0.0/16
        - IpProtocol: tcp
          FromPort: 2380
          ToPort: 2380
          Description: etcd
          CidrIp: 10.5.0.0/16
        - IpProtocol: tcp
          FromPort: 10250
          ToPort: 10250
          Description: kubelet
          CidrIp: 10.5.0.0/16
        - IpProtocol: tcp
          FromPort: 10251
          ToPort: 10251
          Description: kube-scheduler
          CidrIp: 10.5.0.0/16
        - IpProtocol: tcp
          FromPort: 10252
          ToPort: 10252
          Description: kube-controller-manager
          CidrIp: 10.5.0.0/16
          # k8s pod NW
        - IpProtocol: tcp
          FromPort: 0
          ToPort: 65535
          Description: kube-controller-manager
          CidrIp: 192.168.0.0/16

  # k8s worker node用SG
  EC2WorkerSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: ec2-worker-sg-cf
      GroupDescription: Allow SSH and HTTP and kubernetes worker access
      VpcId: !Ref VPC
      SecurityGroupIngress:
        # ssh
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: !Ref MyIP
        # k8s
        - IpProtocol: tcp
          FromPort: 10250
          ToPort: 10250
          Description: kubelet
          CidrIp: 10.5.0.0/16
        - IpProtocol: tcp
          FromPort: 30000
          ToPort: 32767
          Description: NodePort Services
          CidrIp: 10.5.0.0/16
        - IpProtocol: tcp
          FromPort: 10250
          ToPort: 10250
          Description: kubelet
          CidrIp: 192.168.0.0/16
        - IpProtocol: tcp
          FromPort: 30000
          ToPort: 32767
          Description: NodePort Services
          CidrIp: 192.168.0.0/16
        # 動作確認用node port
        - IpProtocol: tcp
          FromPort: 30000
          ToPort: 32767
          CidrIp: !Ref MyIP

  EC2IAMRole: 
    Type: AWS::IAM::Role
    Properties: 
      RoleName: ec2-role-cf
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: Allow
            Principal: 
              Service: 
                - "ec2.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"
      ManagedPolicyArns: 
        # 検証用なのでAdmin権限付与
        - "arn:aws:iam::aws:policy/AdministratorAccess"

  EC2InstanceProfile: 
    Type: AWS::IAM::InstanceProfile
    Properties: 
      Path: "/"
      Roles: 
        - Ref: EC2IAMRole
      InstanceProfileName: ec2-instance-profile-cf


Outputs:
  EC2PublicIP1:
    Value: !GetAtt EC2Master1.PublicIp
    Description: Public IP of EC2 instance
  EC2PublicIP2:
    Value: !GetAtt EC2Master2.PublicIp
    Description: Public IP of EC2 instance
  EC2PublicIP3:
    Value: !GetAtt EC2Master3.PublicIp
    Description: Public IP of EC2 instance
  EC2Worker1:
    Value: !GetAtt EC2Worker1.PublicIp
    Description: Public IP of EC2 instance

